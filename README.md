# DataScience_MidCourse_12_22
ë°ì´í„° ë¶„ì„ ë° ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ ë¹„êµ ì‹¤í—˜ í”„ë¡œì íŠ¸

# ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤ ì¤‘ê¸‰ 12_22

## ğŸ“Œ ê°œìš”
ì´ í”„ë¡œì íŠ¸ëŠ” **ì‹¤ì œ ë°ì´í„°ë¥¼ í™œìš©í•œ ë¶„ì„ ë° ë‹¤ì–‘í•œ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ ë¹„êµ**ë¥¼ ìˆ˜í–‰í•œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.
EDA(íƒìƒ‰ì  ë°ì´í„° ë¶„ì„), íšŒê·€ ë¶„ì„, ì˜ì‚¬ê²°ì • íŠ¸ë¦¬, SVM, ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë“±ì˜ ëª¨ë¸ì„ ì‹¤í—˜ì ìœ¼ë¡œ ì ìš©í•´ ë³´ì•˜ìŠµë‹ˆë‹¤.

## ğŸ› ï¸ ì‚¬ìš©í•œ ê¸°ìˆ 
- `Statsmodels` ë° `Scikit-learn`ì„ í™œìš©í•œ ë¦¿ì§€, ë¼ì†Œ íšŒê·€ ë¶„ì„
- `Matplotlib`, `Seaborn`ì„ í™œìš©í•œ ë°ì´í„° ì‹œê°í™”
- `DecisionTreeClassifier`, `SVC`, `RandomForestClassifier`ë¥¼ í™œìš©í•œ ë¶„ë¥˜ ëª¨ë¸ ë¹„êµ
- Confusion Matrix, Precision, Recall, F1-score ë“± ì„±ëŠ¥ í‰ê°€ ì§€í‘œ í™œìš©
- Google Colab í™˜ê²½ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥

---

## ğŸ”¹ ì£¼ìš” ì‹¤í—˜ ë‚´ìš©

### 1ï¸âƒ£ EDA ë° íšŒê·€ ë¶„ì„ (ë¦¿ì§€ & ë¼ì†Œ)
- ë°ì´í„° ì „ì²˜ë¦¬ ë° íƒìƒ‰ì  ë°ì´í„° ë¶„ì„
- OLS(ìµœì†Œì œê³±ë²•)ê³¼ ì •ê·œí™”ëœ ë¦¿ì§€ ë° ë¼ì†Œ íšŒê·€ ì ìš©
- ë¦¿ì§€ íšŒê·€ ê³„ìˆ˜ì™€ ë¼ì†Œ íšŒê·€ ê³„ìˆ˜ì˜ ë³€í™” ë¹„êµ

#### âœ”ï¸ ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ (ë¦¿ì§€ íšŒê·€ ë¶„ì„)
```python
import statsmodels.api as sm
import numpy as np
import pandas as pd
from sklearn import datasets

# ë‹¹ë‡¨ë³‘ ë°ì´í„°ì…‹ ë¡œë“œ
diabetes_data = datasets.load_diabetes()
df = pd.DataFrame(diabetes_data.data, columns=diabetes_data.feature_names)
df['target'] = diabetes_data.target

# ì ˆí¸(intercept) ì¶”ê°€
X = sm.add_constant(df.drop('target', axis=1))
y = df['target']

# ë¦¿ì§€ íšŒê·€ ìˆ˜í–‰
ridge_regression = sm.OLS(y, X).fit_regularized(L1_wt=0, alpha=1.0)
print(ridge_regression.params)
```

#### âœ”ï¸ ê²°ê³¼

- ë¦¿ì§€ íšŒê·€ ê³„ìˆ˜ì™€ ë¼ì†Œ íšŒê·€ ê³„ìˆ˜ì˜ ì°¨ì´ë¥¼ ë¹„êµí•˜ëŠ” ê·¸ë˜í”„ ì¶œë ¥
- (ì´ë¯¸ì§€ê²°ê³¼_1.png), (ì´ë¯¸ì§€ê²°ê³¼_2.png)

---

### 2ï¸âƒ£ ì˜ì‚¬ê²°ì • íŠ¸ë¦¬ (Decision Tree)
- `DecisionTreeClassifier`ë¥¼ í™œìš©í•œ ëª¨ë¸ í•™ìŠµ ë° ì‹œê°í™”
- Confusion Matrixë¥¼ í†µí•´ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€

#### âœ”ï¸ ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
```python
from sklearn.tree import DecisionTreeClassifier, plot_tree
import matplotlib.pyplot as plt

# ëª¨ë¸ í•™ìŠµ ë° ì‹œê°í™”
model = DecisionTreeClassifier(max_depth=2, random_state=0)
model.fit(X, y)
plt.figure(figsize=(20,10))
plot_tree(model, filled=True)
plt.show()
```

#### âœ”ï¸ ê²°ê³¼
- ì˜ì‚¬ê²°ì • íŠ¸ë¦¬ êµ¬ì¡° ì‹œê°í™”
- `ì´ë¯¸ì§€ê²°ê³¼_3.png`, `ì´ë¯¸ì§€ê²°ê³¼_4.png`

---

### 3ï¸âƒ£ SVM (Support Vector Machine)
- SVMì„ í™œìš©í•œ ë°ì´í„° ë¶„ë¥˜
- Confusion Matrix ë° ì„±ëŠ¥ ì§€í‘œ ì¶œë ¥

#### âœ”ï¸ ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
```python
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# SVM ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
model = SVC(kernel='linear', C=1.0, random_state=0)
model.fit(X_train, y_train)

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Model accuracy: {accuracy:.2f}')
```

#### âœ”ï¸ ê²°ê³¼
- SVMì˜ ë¶„ë¥˜ ì„±ëŠ¥ ì‹œê°í™” ë° Confusion Matrix
- `ì´ë¯¸ì§€ê²°ê³¼_5.png`, `ì´ë¯¸ì§€ê²°ê³¼_6.png`

---

### 4ï¸âƒ£ ëœë¤ í¬ë ˆìŠ¤íŠ¸ (Random Forest)
- `RandomForestClassifier`ë¥¼ í™œìš©í•œ ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜
- ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ (ì •ë°€ë„, ì¬í˜„ìœ¨, F1-score ì¶œë ¥)

#### âœ”ï¸ ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
rf_model = RandomForestClassifier(n_estimators=100, random_state=0)
rf_model.fit(X_train, y_train)

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
y_pred_rf = rf_model.predict(X_test)
print(classification_report(y_test, y_pred_rf))
```

#### âœ”ï¸ ê²°ê³¼
- Random Forest ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
- `ì´ë¯¸ì§€ê²°ê³¼_7.png`

---

## ğŸ”— ê´€ë ¨ ê¸°ìˆ  ë° íŒ¨í‚¤ì§€
- `Scikit-learn`
- `Statsmodels`
- `Matplotlib`
- `Seaborn`
- `NumPy`, `Pandas`
